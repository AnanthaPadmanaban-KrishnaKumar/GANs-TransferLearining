{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41017bad-d5cd-498b-ae79-c36035419159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D, BatchNormalization\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c458b99-4774-4770-8f78-f560b866d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG19(include_top=False, input_shape=(224, 224, 3))\n",
    "vgg.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be42fa80-665c-4a41-a119-c8e9428c86e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    model = Sequential()\n",
    "    # Beginnings of a generated image\n",
    "    model.add(Dense(7*7*1024, input_dim=100))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Reshape((7, 7,1024)))\n",
    "    \n",
    "    # 1 \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(1024, 4, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # 2\n",
    "    model.add(Conv2D(1024, 4, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    # model.add(Conv2D(1024, 4, padding='same'))\n",
    "    # model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # 3\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(512, 4, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    # model.add(Conv2D(512, 4, padding='same'))\n",
    "    # model.add(LeakyReLU(0.2))\n",
    "\n",
    "    # 4\n",
    "    model.add(Conv2D(512, 4, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    \n",
    "    # 5\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256, 4, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    # model.add(Conv2D(256, 4, padding='same'))\n",
    "    # model.add(LeakyReLU(0.2))\n",
    "\n",
    "    #6\n",
    "    model.add(Conv2D(256, 4, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    # model.add(Conv2D(256, 4, padding='same'))\n",
    "    # model.add(LeakyReLU(0.2))\n",
    "\n",
    "    #7\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, 4, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    #8\n",
    "    model.add(Conv2D(128, 4, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    # model.add(Conv2D(128, 4, padding='same'))\n",
    "    # model.add(LeakyReLU(0.2))\n",
    "\n",
    "    #9\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, 4, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    # model.add(Conv2D(64, 4, padding='same'))\n",
    "    # model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # Conv layer to get to one channel\n",
    "    model.add(Conv2D(1, 3, padding='same', activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bcb393d-4272-4962-97eb-73833db59a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e892b7d-24e5-467f-bebc-6502ddbc433a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50176)             5067776   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 50176)             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2  (None, 14, 14, 1024)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 14, 14, 1024)      16778240  \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 14, 14, 1024)      4096      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 14, 14, 1024)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 1024)      16778240  \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 14, 14, 1024)      4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 14, 14, 1024)      0         \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSamplin  (None, 28, 28, 1024)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 512)       8389120   \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 28, 28, 512)       2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 512)       4194816   \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 28, 28, 512)       2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSamplin  (None, 56, 56, 512)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 56, 56, 256)       2097408   \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 56, 56, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 56, 56, 256)       1048832   \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 56, 56, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 56, 56, 256)       0         \n",
      "                                                                 \n",
      " up_sampling2d_3 (UpSamplin  (None, 112, 112, 256)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 112, 112, 128)     524416    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 112, 112, 128)     512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 112, 112, 128)     0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 112, 112, 128)     262272    \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 112, 112, 128)     512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 112, 112, 128)     0         \n",
      "                                                                 \n",
      " up_sampling2d_4 (UpSamplin  (None, 224, 224, 128)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 224, 224, 64)      131136    \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 224, 224, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 224, 224, 1)       577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55288449 (210.91 MB)\n",
      "Trainable params: 55280641 (210.88 MB)\n",
      "Non-trainable params: 7808 (30.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "151de5f0-6dd8-4a52-a83c-69dcc8cbf88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "        vgg,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1024),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb915f6f-d26d-4207-b1e0-58c983d3b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd53c677-f871-45d5-a19c-6c9a1f915d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              25691136  \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45716545 (174.39 MB)\n",
      "Trainable params: 25692161 (98.01 MB)\n",
      "Non-trainable params: 20024384 (76.39 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6e45269-495b-4061-8566-7939d7df94a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionGAN(Model): \n",
    "    def __init__(self, generator, discriminator, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.generator = generator \n",
    "        self.discriminator = discriminator \n",
    "        \n",
    "    def compile(self, g_opt, d_opt, g_loss, d_loss, *args, **kwargs): \n",
    "        super().compile(*args, **kwargs)\n",
    "        \n",
    "        self.g_opt = g_opt\n",
    "        self.d_opt = d_opt\n",
    "        self.g_loss = g_loss\n",
    "        self.d_loss = d_loss \n",
    "\n",
    "    def train_step(self, batch):\n",
    "        # Get the data \n",
    "        real_images = batch\n",
    "        fake_images = self.generator(tf.random.normal((224, 224, 1)), training=False)\n",
    "        with tf.GradientTape() as d_tape: \n",
    "            yhat_real = self.discriminator(real_images, training=True) \n",
    "            yhat_fake = self.discriminator(fake_images, training=True)\n",
    "            yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0)\n",
    "            y_realfake = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis=0)\n",
    "            noise_real = 0.15*tf.random.uniform(tf.shape(yhat_real))\n",
    "            noise_fake = -0.15*tf.random.uniform(tf.shape(yhat_fake))\n",
    "            y_realfake += tf.concat([noise_real, noise_fake], axis=0)\n",
    "            \n",
    "            # Calculate loss - BINARYCROSS \n",
    "            total_d_loss = self.d_loss(y_realfake, yhat_realfake)\n",
    "            \n",
    "        dgrad = d_tape.gradient(total_d_loss, self.discriminator.trainable_variables) \n",
    "        self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n",
    "        \n",
    "        # Train the generator \n",
    "        with tf.GradientTape() as g_tape: \n",
    "            # Generate some new images\n",
    "            gen_images = self.generator(tf.random.normal((224,224,1)), training=True)\n",
    "            predicted_labels = self.discriminator(gen_images, training=False)\n",
    "            total_g_loss = self.g_loss(tf.zeros_like(predicted_labels), predicted_labels) \n",
    "            \n",
    "        # Apply backprop\n",
    "        ggrad = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
    "        self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n",
    "        \n",
    "        return {\"d_loss\":total_d_loss, \"g_loss\":total_g_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "515ac1c4-8279-4cd1-b85e-3c314d0d1c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "g_opt = Adam(learning_rate=0.0001) \n",
    "d_opt = Adam(learning_rate=0.00001) \n",
    "g_loss = BinaryCrossentropy()\n",
    "d_loss = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7d110d2-29dd-46c6-afa7-f401d1ffe362",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashgan = FashionGAN(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c07d90a4-6e09-44d9-b485-456561b1ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashgan.compile(g_opt, d_opt, g_loss, d_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4a872ac-692e-499b-a6b0-6e35e8660167",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMonitor(Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=100):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.uniform((self.num_img, self.latent_dim,1))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = array_to_img(generated_images[i])\n",
    "            img.save(os.path.join('images', f'generated_img_{epoch}_{i}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31330d9-3759-4e9e-b3cd-c2113d4483c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = fashgan.fit(data, epochs=2000, callbacks=[ModelMonitor()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
